{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E-kwR3NwiBcQ"
   },
   "outputs": [],
   "source": [
    "# global config variables\n",
    "img_dir_gdrive = \"/content/drive/MyDrive/ML_IoT\"\n",
    "img_dir_local = \"./data\"\n",
    "\n",
    "words = [ \"people\", \"happy\", \"unknown\" ]\n",
    "\n",
    "i16min = -2**15\n",
    "i16max = 2**15-1\n",
    "fsamp = 16000\n",
    "use_microfrontend = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mS7kmmPtfqlQ",
    "outputId": "3b8bd36b-f444-44ed-d26a-b1ca61b8b6d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "\u001b[31mERROR: Requested seaborn from https://files.pythonhosted.org/packages/68/ad/6c2406ae175f59ec616714e408979b674fe27b9587f79d59a528ddfbcd5b/seaborn-0.11.1-py3-none-any.whl#sha256=4e1cce9489449a1c6ff3c567f2113cdb41122f727e27a984950d004a88ef3c5c has different version in metadata: '0.11.1'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install nessicary libraries\n",
    "!pip install --ignore-installed seaborn #tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mi-aHptRhGHo",
    "outputId": "e6bc14ee-6036-4d78-9191-81f84d69f135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import time\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import random\n",
    "# import tensorflow_io as tfio\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.lite.experimental.microfrontend.python.ops import audio_microfrontend_op as frontend_op\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_dir = img_dir_gdrive\n",
    "except:\n",
    "    data_dir = img_dir_local\n",
    "    \n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "seed = int(time.time())\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jspy8hEkhxz_"
   },
   "outputs": [],
   "source": [
    "# copy over all the custom speach data from drive to local storage\n",
    "if not os.path.exists(\"./training\"):\n",
    "  print(\"Copying over audio data\")\n",
    "  os.mkdir(\"training\")\n",
    "  shutil.copytree(f\"{data_dir}/people_raw/\", \"./training/people\")\n",
    "  shutil.copytree(f\"{data_dir}/happy_raw/\", \"./training/happy\")\n",
    "  shutil.copytree(f\"{data_dir}/unknown_raw/\", \"./training/unknown\")\n",
    "  print(\"Copied over audio data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People:\n",
      "\t Total: 1692\n",
      "\t Train: 1269\n",
      "\t Valid: 169\n",
      "\t Test: 254\n",
      "Happy:\n",
      "\t Total: 2054\n",
      "\t Train: 1540\n",
      "\t Valid: 205\n",
      "\t Test: 309\n",
      "Unknown:\n",
      "\t Total: 2736\n",
      "\t Train: 2052\n",
      "\t Valid: 273\n",
      "\t Test: 411\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1269] vs. [1540] [Op:Add]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-33ba5add8094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mtrain_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeople_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhappy_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munknown_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mvalid_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeople_valid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhappy_valid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munknown_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mtest_filenames\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpeople_test\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhappy_test\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munknown_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1269] vs. [1540] [Op:Add]"
     ]
    }
   ],
   "source": [
    "# Create our training, validation and test sets\n",
    "train_percent = 0.75\n",
    "valid_percent = 0.1\n",
    "test_percent  = 0.15\n",
    "\n",
    "print(\"People:\")\n",
    "# get file names\n",
    "people_filenames = tf.io.gfile.glob('./training/people/*')\n",
    "people_filenames = tf.random.shuffle(people_filenames)\n",
    "length = len(people_filenames)\n",
    "print(f\"\\t Total: { length }\")\n",
    "# cut out training set\n",
    "idx = int(math.floor(length * train_percent))\n",
    "people_train = people_filenames[: idx ]\n",
    "people_filenames = people_filenames[ idx :]\n",
    "print(f\"\\t Train: { len(people_train) }\")\n",
    "# cut out validation set\n",
    "idx = int(math.floor(length * valid_percent))\n",
    "people_valid = people_filenames[: idx ]\n",
    "people_filenames = people_filenames[ idx :]\n",
    "print(f\"\\t Valid: { len(people_valid) }\")\n",
    "# the rest is the test set\n",
    "people_test = people_filenames\n",
    "print(f\"\\t Test: { len(people_test) }\")\n",
    "\n",
    "\n",
    "print(\"Happy:\")\n",
    "happy_filenames = tf.io.gfile.glob('./training/happy/*')\n",
    "happy_filenames = tf.random.shuffle(happy_filenames)\n",
    "length = len(happy_filenames)\n",
    "print(f\"\\t Total: { length }\")\n",
    "# cut out training set\n",
    "idx = int(math.floor(length * train_percent))\n",
    "happy_train = happy_filenames[: idx ]\n",
    "happy_filenames = happy_filenames[ idx :]\n",
    "print(f\"\\t Train: { len(happy_train) }\")\n",
    "# cut out validation set\n",
    "idx = int(math.floor(length * valid_percent))\n",
    "happy_valid = happy_filenames[: idx ]\n",
    "happy_filenames = happy_filenames[ idx :]\n",
    "print(f\"\\t Valid: { len(happy_valid) }\")\n",
    "# the rest is the test set\n",
    "happy_test = happy_filenames\n",
    "print(f\"\\t Test: { len(happy_test) }\")\n",
    "\n",
    "\n",
    "print(\"Unknown:\")\n",
    "unknown_filenames = tf.io.gfile.glob('./training/unknown/*')\n",
    "unknown_filenames = tf.random.shuffle(unknown_filenames)\n",
    "length = len(unknown_filenames)\n",
    "print(f\"\\t Total: { length }\")\n",
    "# cut out training set\n",
    "idx = int(math.floor(length * train_percent))\n",
    "unknown_train = unknown_filenames[: idx ]\n",
    "unknown_filenames = unknown_filenames[ idx :]\n",
    "print(f\"\\t Train: { len(unknown_train) }\")\n",
    "# cut out validation set\n",
    "idx = int(math.floor(length * valid_percent))\n",
    "unknown_valid = unknown_filenames[: idx ]\n",
    "unknown_filenames = unknown_filenames[ idx :]\n",
    "print(f\"\\t Valid: { len(unknown_valid) }\")\n",
    "# the rest is the test set\n",
    "unknown_test = unknown_filenames\n",
    "print(f\"\\t Test: { len(unknown_test) }\")\n",
    "\n",
    "\n",
    "train_filenames = people_train + happy_train + unknown_train\n",
    "valid_filenames = people_valid + happy_valid + unknown_valid \n",
    "test_filenames  = people_test + happy_test + unknown_test \n",
    "print(f\"Total Train: { len(train_filenames) }\")\n",
    "print(f\"Total Valid: { len(valid_filenames) }\")\n",
    "print(f\"Total Test:  { len(test_filenames) }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "    audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "    return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "def get_label(file_path):\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  return parts[-2]\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform = decode_audio(audio_binary)\n",
    "    return waveform, label\n",
    "\n",
    "def wavds2specds(waveform_ds):\n",
    "  spec_grams = np.zeros((0, 49, 40, 1))\n",
    "  labels = []\n",
    "  for wav, label in waveform_ds:\n",
    "    spectrogram = get_spectrogram(wav)\n",
    "    # TF conv layer expect inputs structured as 4D (batch_size, height, width, channels)\n",
    "    # the microfrontend returns 2D tensors (freq, time), so we need to \n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=0)  # add a 'batch' dimension at the front\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=-1) # add a singleton 'channel' dimension at the back\n",
    "    spec_grams = np.concatenate((spec_grams, spectrogram))\n",
    "    new_label = label.numpy().decode('utf8')\n",
    "    new_label_id = np.argmax(new_label == words)\n",
    "    labels.append(new_label_id) # for numeric labels\n",
    "    # labels.append(new_label) # for string labels\n",
    "  return tf.data.Dataset.from_tensor_slices((spec_grams, labels))\n",
    "\n",
    "def get_spectrogram(waveform):\n",
    "    # Padding for files with less than 16000 samples\n",
    "    zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.float32)\n",
    "    equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "    spectrogram = tf.signal.stft(equal_length, frame_length=255, frame_step=128)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    \n",
    "#     zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.int16)\n",
    "#     equal_length = tf.cast(0.5*waveform*(i16max-i16min), tf.int16)  # scale float [-1,+1]=>INT16\n",
    "#     equal_length = tf.concat([equal_length, zero_padding], 0)\n",
    "#     spectrogram = frontend_op.audio_microfrontend(\n",
    "#         equal_length, sample_rate=fsamp, num_channels=40,\n",
    "#         window_size=40, window_step=20)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "def plot_spectrogram(spectrogram, ax):\n",
    "    # Convert to frequencies to log scale and transpose so that the time is\n",
    "    # represented in the x-axis (columns).\n",
    "    log_spec = np.log(spectrogram.T)\n",
    "    height = log_spec.shape[0]\n",
    "    width = log_spec.shape[1]\n",
    "    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "    Y = range(height)\n",
    "    ax.pcolormesh(X, Y, log_spec, shading='auto')\n",
    "    \n",
    "#     freq_bins = spectrogram.shape[1]\n",
    "#     time_dur = spectrogram.shape[0]\n",
    "#     X = np.arange(time_dur)\n",
    "#     Y = range(freq_bins)\n",
    "#     ax.pcolormesh(X, Y, spectrogram.T)\n",
    "    \n",
    "def get_spectrogram_and_label_id(audio, label):\n",
    "    spectrogram = get_spectrogram(audio)\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    label_id = tf.argmax(label == words)\n",
    "    return spectrogram, label_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkIjThnXk9fX"
   },
   "outputs": [],
   "source": [
    "# Display 9 waveforms\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\n",
    "files_ds = files_ds.shuffle(len(train_filenames))\n",
    "waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "spectrogram_ds = waveform_ds.map(get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "#train_ds = wavds2specds(waveform_ds)\n",
    "\n",
    "rows = 3\n",
    "cols = 3\n",
    "n = rows*cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 12))\n",
    "for i, (audio, label) in enumerate(waveform_ds.take(n)):\n",
    "  r = i // cols\n",
    "  c = i % cols\n",
    "  ax = axes[r][c]\n",
    "  ax.plot(audio.numpy())\n",
    "  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "  label = label.numpy().decode('utf-8')\n",
    "  ax.set_title(label)\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display one of each word clip\n",
    "shown = [ False, False, False ]\n",
    "fig, axes = plt.subplots(6, figsize=(12, 36))\n",
    "current_axis = 0\n",
    "\n",
    "for waveform, label in waveform_ds:\n",
    "    if not False in shown:\n",
    "        break\n",
    "        \n",
    "    if shown[words.index(label)] == False:\n",
    "        print('Label:', label)\n",
    "        label = label.numpy().decode('utf-8')\n",
    "        print('Waveform shape:', waveform.shape)\n",
    "        spectrogram = get_spectrogram(waveform)\n",
    "        print('Spectrogram shape:', spectrogram.shape)\n",
    "        print('Audio playback')\n",
    "        display.display(display.Audio(waveform, rate=16000))\n",
    "        shown[words.index(label)] = True\n",
    "        \n",
    "        timescale = np.arange(waveform.shape[0])\n",
    "        axes[current_axis].plot(timescale, waveform.numpy())\n",
    "        axes[current_axis].set_title('Waveform')\n",
    "        axes[current_axis].set_xlim([0, 16000])\n",
    "        plot_spectrogram(spectrogram.numpy(), axes[current_axis + 1])\n",
    "        axes[current_axis + 1].set_title('Spectrogram')\n",
    "        current_axis += 2\n",
    "        \n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish seting up the datasets\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\n",
    "waveform_ds = files_ds.map(get_waveform_and_label)\n",
    "train_ds = waveform_ds.map(get_spectrogram_and_label_id)\n",
    "# train_ds = wavds2specds(waveform_ds)\n",
    "\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(valid_filenames)\n",
    "waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "valid_ds = waveform_ds.map(get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "# valid_ds = wavds2specds(waveform_ds)\n",
    "\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(test_filenames)\n",
    "waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = waveform_ds.map(get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "# test_ds = wavds2specds(waveform_ds)\n",
    "\n",
    "batch_size = 64\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "valid_ds = valid_ds.batch(batch_size)\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "valid_ds = valid_ds.cache().prefetch(AUTOTUNE)\n",
    "\n",
    "for spectrogram, _ in train_ds.take(1):\n",
    "  spec1 = spectrogram\n",
    "# take(1) takes 1 *batch*, so we have to select the first \n",
    "# spectrogram from it, hence the [0]\n",
    "print(f\"Spectrogram shape {spec1[0].shape}\")\n",
    "print(f\"ranges from {np.min(spec1)} to {np.max(spec1)}\")   # min/max across the whole batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spectrogram, _ in train_ds.take(1):\n",
    "  # take(1) takes 1 *batch*, so we have to select the first \n",
    "  # spectrogram from it, hence the [0]\n",
    "  input_shape = spectrogram[0].shape  \n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(words)\n",
    "\n",
    "# norm_layer = preprocessing.Normalization()\n",
    "# norm_layer.adapt(train_ds.map(lambda x, _: x))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(name='pool2'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(4,4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,  \n",
    "    epochs=EPOCHS,\n",
    "    #callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.epoch, metrics['accuracy'], metrics['val_accuracy'])\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio = []\n",
    "test_labels = []\n",
    "\n",
    "for audio, label in test_ds:\n",
    "  test_audio.append(audio.numpy())\n",
    "  test_labels.append(label.numpy())\n",
    "\n",
    "test_audio = np.array(test_audio)\n",
    "test_labels = np.array(test_labels)\n",
    "y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
    "y_true = test_labels\n",
    "\n",
    "test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "print(f'Test set accuracy: {test_acc:.0%}')\n",
    "\n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred) \n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx, xticklabels=words, yticklabels=words, \n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = f\"./training/people/people-01.wav\"\n",
    "\n",
    "\n",
    "files_ds = tf.data.Dataset.from_tensor_slices([ sample_file ])\n",
    "files_ds = files_ds.shuffle(len(train_filenames))\n",
    "waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "final_ds = waveform_ds.map(get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "for spectrogram, label in final_ds.batch(1):\n",
    "  prediction = model(spectrogram)\n",
    "  plt.bar(words, tf.nn.softmax(prediction[0]))\n",
    "  plt.title(f'Predictions for \"{words[label[0]]}\"')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to TFLite\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# num_calibration_steps = 10\n",
    "# ds_iter = valid_ds.unbatch().batch(1).as_numpy_iterator()\n",
    "# def representative_dataset_gen():\n",
    "#   for _ in range(num_calibration_steps):\n",
    "#     next_input = next(ds_iter)[0]\n",
    "#     next_input = next_input.astype(np.float32)  # (DIFF_FROM_LECTURE)\n",
    "#     yield [next_input]\n",
    "    \n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.representative_dataset = representative_dataset_gen\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter.inference_input_type = tf.int8  # or tf.uint8; should match dat_q in eval_quantized_model.py\n",
    "# converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "# tflite_quant_model = converter.convert()\n",
    "\n",
    "# fname = 'kws_model.tflite'\n",
    "# with open(fname, \"wb\") as fpo:\n",
    "#   num_bytes_written = fpo.write(tflite_quant_model)\n",
    "# print(f\"Wrote {num_bytes_written} / {len(tflite_quant_model)} bytes to tflite file\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
